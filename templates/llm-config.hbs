<form class="llm-config-form">
    <div class="form-group">
        <label for="provider">LLM Provider</label>
        <select name="provider" id="provider">
            <option value="openai" {{#if isOpenAI}}selected{{/if}}>OpenAI</option>
            <option value="anthropic" {{#if isAnthropic}}selected{{/if}}>Anthropic</option>
            <option value="local" {{#if isLocal}}selected{{/if}}>Local (Ollama/LM Studio)</option>
        </select>
        <p class="notes">Choose which LLM provider to use for {{#if (eq configType 'actionCache')}}generating cached action descriptions{{else}}combat recommendations{{/if}}</p>
    </div>

    <!-- API Key (for OpenAI and Anthropic) -->
    <div class="form-group api-key-group" style="{{#if isLocal}}display:none;{{/if}}">
        <label for="apiKey">API Key</label>
        <input type="password" name="apiKey" value="{{apiKey}}" placeholder="{{#if isOpenAI}}sk-...{{else}}sk-ant-...{{/if}}">
        <p class="notes">Your API key. Keep this secure!</p>
    </div>

    <!-- Model Name (universal) -->
    <div class="form-group">
        <label for="model">Model</label>
        <input type="text" name="model" value="{{model}}" placeholder="{{#if isOpenAI}}gpt-4o-mini{{else if isAnthropic}}claude-3-5-haiku-20241022{{else}}llama3.2{{/if}}" list="model-suggestions">
        <datalist id="model-suggestions">
            {{#if isOpenAI}}
                <option value="gpt-4o-mini">
                <option value="gpt-4o">
                <option value="o1-mini">
                <option value="o1">
            {{else if isAnthropic}}
                <option value="claude-3-5-haiku-20241022">
                <option value="claude-3-5-sonnet-20241022">
                <option value="claude-opus-4-20250514">
            {{else}}
                <option value="llama3.2">
                <option value="llama3.2:13b">
                <option value="mistral">
                <option value="codellama">
            {{/if}}
        </datalist>
        <p class="notes">
            {{#if isOpenAI}}
                Examples: gpt-4o-mini, gpt-4o, o1-mini, o1
            {{else if isAnthropic}}
                Examples: claude-3-5-haiku-20241022, claude-3-5-sonnet-20241022, claude-opus-4-20250514
            {{else}}
                Model name from your local server (e.g., llama3.2, mistral)
            {{/if}}
        </p>
    </div>

    <!-- Max Tokens -->
    <div class="form-group">
        <label for="maxTokens">Max Tokens</label>
        <input type="number" name="maxTokens" value="{{maxTokens}}" min="100" max="16000">
        <p class="notes">Maximum response length (tokens)</p>
    </div>

    <!-- Reasoning Effort (for O1 models) -->
    <div class="form-group reasoning-group" style="{{#unless isOpenAI}}display:none;{{/unless}}">
        <label for="reasoningEffort">Reasoning Effort (O1 models only)</label>
        <select name="reasoningEffort">
            <option value="low" {{#if (eq reasoningEffort 'low')}}selected{{/if}}>Low</option>
            <option value="medium" {{#if (eq reasoningEffort 'medium')}}selected{{/if}}>Medium</option>
            <option value="high" {{#if (eq reasoningEffort 'high')}}selected{{/if}}>High</option>
        </select>
        <p class="notes">How much reasoning effort to apply (only for O1 models, ignored otherwise)</p>
    </div>

    <!-- Local Endpoint -->
    <div class="form-group local-group" style="{{#unless isLocal}}display:none;{{/unless}}">
        <label for="localEndpoint">Local API Endpoint</label>
        <input type="text" name="localEndpoint" value="{{localEndpoint}}" placeholder="http://localhost:11434">
        <p class="notes">URL for your local LLM server (Ollama, LM Studio, etc.)</p>
    </div>

    <button type="submit"><i class="fas fa-save"></i> Save Configuration</button>
</form>
